{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import device as device_\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "if torch.cuda.is_available() :\n",
    "    device='cuda'\n",
    "else: device='cpu'\n",
    "##device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139568, 395)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_stata('data/gruber_subset.dta', convert_categoricals=False)\n",
    "df.describe()\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "#df.describe()\n",
    "#train_x = torch.tensor(df[['lat', 'lon']].values).to(device)\n",
    "#train_y = torch.tensor(df.ddd.values).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whiten the Necessary Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for j in range(0,5): \n",
    "    \n",
    "    start = time.time() # timet the main loop\n",
    "\n",
    "    df_dicts[j] = df.sample(n=10000, random_state=j) \n",
    "    df_dicts[j].to_stata(f'data/gruber_org_cuda_{j}.dta', write_index=False)\n",
    "\n",
    "'''\n",
    "chunks = [df.iloc[i:i+10000, :] for i in range(0, len(df), 10000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Chunk: 1 in 42.92758235534032 minutes\n",
      "Done with Chunk: 2 in 38.64309225877126 minutes\n",
      "Done with Chunk: 3 in 41.91689244111379 minutes\n",
      "Done with Chunk: 4 in 42.33911789655686 minutes\n",
      "Done with Chunk: 5 in 41.45989835659663 minutes\n",
      "Done with Chunk: 6 in 42.84209967851639 minutes\n",
      "Done with Chunk: 7 in 40.658673950036366 minutes\n",
      "Done with Chunk: 8 in 43.39113495747248 minutes\n",
      "Done with Chunk: 9 in 39.94662171999614 minutes\n",
      "Done with Chunk: 10 in 40.6848464290301 minutes\n",
      "Done with Chunk: 11 in 40.79162955681483 minutes\n",
      "Done with Chunk: 12 in 42.59656974871953 minutes\n",
      "Done with Chunk: 13 in 41.624030029773714 minutes\n",
      "Done with Chunk: 14 in 37.437859416007996 minutes\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "counter = 1 \n",
    "for j in chunks: \n",
    "    \n",
    "    j.name = str(counter) # give the chunk a name\n",
    "    \n",
    "    \n",
    "    start = time.time() # timet the main loop\n",
    "    \n",
    "    df2 = pd.DataFrame().reindex_like(j) # empty dataset like \n",
    "\n",
    "    target = ['lat', 'lon']\n",
    "    consider = [x for x in df.columns if x not in target]\n",
    "    #print(consider)\n",
    "\n",
    "\n",
    "    # train x is always latitude and longitude \n",
    "    train_x = torch.tensor(j[['lat', 'lon']].values).type(dtype).to(device)\n",
    "\n",
    "    for x in consider:\n",
    "\n",
    "        train_y = torch.tensor(j[x].values).type(dtype).to(device)\n",
    "\n",
    "        '''\n",
    "        run the gpytorch code here \n",
    "        '''\n",
    "        # Find optimal model hyperparameters\n",
    "\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = ExactGPModel(train_x, train_y, likelihood).to(device)\n",
    "\n",
    "        # Find optimal model hyperparameters\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=0.1)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=0.1)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        training_iterations = 30\n",
    "\n",
    "        #start = time.time() # timet the main loop\n",
    "\n",
    "        for i in range(training_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            # print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        # making prediction \n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            prediction = likelihood(model(train_x))\n",
    "\n",
    "            y_hat = prediction.mean\n",
    "            res = train_y - y_hat \n",
    "\n",
    "\n",
    "            #append to the dataset \n",
    "            df2[x] = res.cpu().numpy()\n",
    "\n",
    "            #torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Done with Chunk: {counter} in {(time.time()-start)/60.0} minutes\")\n",
    "    \n",
    "    df2.describe()\n",
    "    df2.to_stata(f'data/whitened_chunk_{j.name}.dta', write_index=False)\n",
    "    \n",
    "    counter += 1 \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
